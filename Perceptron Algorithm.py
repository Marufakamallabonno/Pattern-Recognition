# -*- coding: utf-8 -*-
"""PR_assm2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16VuN8VB2oVv1n-cw1B2wfbG7CdV3D82i
"""

#1
import matplotlib.pyplot as plt
import numpy as np
train_data =np.loadtxt('/content/drive/MyDrive/4.2/pattern lab /assm2/train-perceptron.txt',dtype='float64');

print(train_data);
#print(test_data);
print(train_data[1][1]);
train_data_c1=[];
train_data_c2=[];
for item in train_data:
    if item[2]==1:
        #print(item[2]);
        train_data_c1.append(item)
    elif item[2]==2:
        train_data_c2.append(item)
train_data_class1= np.array(train_data_c1);
train_data_class2= np.array(train_data_c2);
#
print(train_data_class1);
print(train_data_class2);
x1,y1= train_data_class1[:,0],train_data_class1[:,1];
x2,y2= train_data_class2[:,0],train_data_class2[:,1];
print("x1",x1);
print("x2",x2);
fig=plt.figure(1, figsize=(10,7))
chart1= fig.add_subplot()
chart1.scatter(x1,y1,marker='o',color='r',label='Train class 1');
chart1.scatter(x2,y2,marker='*',color='k',label='Train class 2');

chart1.axis([-5,10,-5,20]);
chart1.legend()#
plt.savefig('TrainClass.png')

#2
classVal=[]
for a in train_data_class1:
  classVal.append(np.array([a[0]*a[0],a[1]*a[1],a[0]*a[1],a[0],a[1],1]))
for a in train_data_class2:
  classVal.append(np.array([a[0]*a[0],a[1]*a[1],a[0]*a[1],a[0],a[1],1])*-1)#normalized class2
for x in classVal:
    print(x)

#3
a=0
eta= np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])
def batchProcessing(weight):
  for z in range(10):
    w=weight
    for count in range(99999999):
      Ysum=np.zeros_like(classVal[0])
      product=np.zeros_like(classVal[0])
      misclass=0 #all classified at first
      for i in range(6): #0 to 5
        wTy= np.dot(classVal[i], w)
        if (wTy <= 0.0):
          misclass=1
          Ysum=classVal[i]+Ysum
      product=Ysum*eta[z]
      w=w +product
      if misclass==0:
        iteration.append( count+1)
        break
#single update
def singleUpdate(weight):
    for z in range(10):
      w=weight
      for count in range(9999999999):
          misclass=0     
          for i in range(6): 
            wTy= np.dot(classVal[i], w)
            if (wTy <= 0.0):
                misclass=1
                Ysum = np.zeros_like(classVal[0])
                Ysum= Ysum + classVal[i]
                product=Ysum*eta[z]
                w=w +product
          if misclass==0:
            iteration1.append( count+1)
            break

#one
print("Initial Weight Vector = All one")
iteration =[]
iteration1 =[]
v=0.1
w=np.ones_like(classVal[0])
batchProcessing(w)  
singleUpdate(w)  
print("Alpha(Learning Rate)"+"\t\t"+"One at a Time"+"\t\t"+'Many at a Time') 
for x in range(10):
  print(format(v, '.1f'),'\t\t\t\t',iteration1[x], "\t\t\t" ,iteration[x])
  v=v+0.1
iteration7 =iteration
iteration8 =iteration1

#zero
print("Initial Weight Vector = All Zero")
v=0.1
iteration =[]
iteration1 =[]
w=np.zeros_like(classVal[0])
batchProcessing(w)  
singleUpdate(w)  
print("Alpha(Learning Rate)"+"\t\t"+"One at a Time"+"\t\t"+'Many at a Time') 
for x in range(10):
  print(format(v, '.1f'),'\t\t\t\t',iteration1[x], "\t\t\t" ,iteration[x])
  v=v+0.1
iteration3 =iteration
iteration4 =iteration1

#random
print("Initial Weight Vector = All random")
iteration =[]
iteration1 =[]
v=0.1
np.random.seed(1)
w = np.random.uniform(0, 1, len(classVal[0]))
batchProcessing(w)  
singleUpdate(w)  
print("Alpha(Learning Rate)"+"\t\t"+"One at a Time"+"\t\t"+'Many at a Time') 
for x in range(10):
  print(format(v, '.1f'),'\t\t\t\t',iteration1[x], "\t\t\t" ,iteration[x])
  v=v+0.1
iteration5 =iteration
iteration6 =iteration1

bar_width = 0.3
index = np.arange(10)
plt.title('Initial Weight Vector All one')
plt.bar(index, iteration8 , bar_width,label='One at a time')
plt.bar(index + bar_width, iteration7 , bar_width, label='Many at a time')
plt.xlabel('Learning Rate')
plt.ylabel('No. of iterations')
plt.xticks(index + bar_width, ('0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9','1.0'))
plt.tight_layout()
plt.legend()
plt.show()
plt.savefig('one.png')
###
bar_width = 0.3
index = np.arange(10)
plt.title('Initial Weight Vector All zero')
plt.bar(index, iteration4 , bar_width,label='One at a time')
plt.bar(index + bar_width, iteration3 , bar_width, label='Many at a time')
plt.xlabel('Learning Rate')
plt.ylabel('No. of iterations')
plt.xticks(index + bar_width, ('0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9','1.0'))
plt.tight_layout()
plt.legend()
plt.show()
plt.savefig('zero.png')
###
bar_width = 0.3
index = np.arange(10)
plt.title('Initial Weight Vector All Random')
plt.bar(index, iteration6, bar_width,label='One at a time')
plt.bar(index + bar_width, iteration5 , bar_width, label='Many at a time')
plt.xlabel('Learning Rate')
plt.ylabel('No. of iterations')
plt.xticks(index + bar_width, ('0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9','1.0'))
plt.tight_layout()
plt.legend()
plt.show()
plt.savefig('random.png')